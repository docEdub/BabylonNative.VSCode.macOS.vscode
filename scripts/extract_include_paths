#!/usr/bin/env python3
"""
Script to extract include paths from compile_commands.json and referenced response files

This script parses a compile_commands.json file (typically generated by CMake or Xcode)
and extracts all include paths from the compiler commands and any referenced response
files (*.resp), then writes unique paths to a .includePaths.log file.

Features:
- Extracts include paths from compile_commands.json and referenced *.resp files
- Supports various include path formats (-I, -isystem, -iframework, -F, --sysroot)
- Configurable glob-based path filtering via IGNORE_PATH_PATTERNS
- Optional filtering of non-existent paths via FILTER_NON_EXISTENT_PATHS
- Outputs paths in c_cpp_properties.json format (quoted, comma-separated)
- Converts workspace-relative paths and absolute paths appropriately
- Clean output suitable for direct copy-paste into VS Code c_cpp_properties.json
"""

import json
import re
import os
import sys
from pathlib import Path
from typing import Set, List
import fnmatch


# Configuration: Paths matching these glob patterns will be ignored
# Add patterns here to exclude specific paths from the include paths output
IGNORE_PATH_PATTERNS = [
    # Examples:
    # "**/build/**",           # Ignore all build directories
    # "**/DerivedSources/**",  # Ignore Xcode derived sources
    # "**/.build/**",          # Ignore CMake build directories
    # "**/3rdparty/**",        # Ignore third-party dependencies
    "**/Debug-iphonesimulator/**"
]

# Configuration: Whether to filter out include paths that don't exist on disk
FILTER_NON_EXISTENT_PATHS = True


def extract_include_paths_from_command(command: str) -> Set[str]:
    """
    Extract include paths from a compiler command string.
    
    Handles various include path formats:
    - -I/path/to/include
    - -I /path/to/include
    - -isystem /path/to/include
    - -iframework /path/to/framework
    - -F/path/to/framework
    """
    include_paths = set()

    # Patterns for different include path formats
    patterns = [
        r'-I\s*([^\s]+)',           # -I/path or -I /path
        r'-isystem\s+([^\s]+)',     # -isystem /path
        r'-iframework\s+([^\s]+)',  # -iframework /path
        r'-F\s*([^\s]+)',           # -F/path or -F /path
        r'--sysroot=([^\s]+)',      # --sysroot=/path
    ]

    for pattern in patterns:
        matches = re.findall(pattern, command)
        for match in matches:
            # Clean up the path
            path = match.strip('"\'')
            if path and path != '.':
                include_paths.add(path)

    return include_paths


def should_ignore_path(path: str) -> bool:
    """
    Check if a path should be ignored based on the configured glob patterns.
    
    Args:
        path: The path to check (can be relative or absolute)
        
    Returns:
        True if the path should be ignored, False otherwise
    """
    if not IGNORE_PATH_PATTERNS:
        return False

    # Normalize path separators for consistent matching
    normalized_path = path.replace('\\', '/')

    for pattern in IGNORE_PATH_PATTERNS:
        # Handle different pattern types
        if pattern.startswith('**/') and pattern.endswith('/**'):
            # Pattern like "**/DerivedSources/**"
            middle_part = pattern[3:-3]  # Remove **/ and /**
            if f'/{middle_part}/' in normalized_path or normalized_path.endswith(f'/{middle_part}') or normalized_path.startswith(f'{middle_part}/'):
                return True
        elif pattern.startswith('**/'):
            # Pattern like "**/something"
            suffix = pattern[3:]
            if normalized_path.endswith(f'/{suffix}') or normalized_path == suffix:
                return True
        elif pattern.endswith('/**'):
            # Pattern like "something/**"
            prefix = pattern[:-3]
            if normalized_path.startswith(f'{prefix}/') or normalized_path == prefix:
                return True
        else:
            # Simple pattern matching
            if fnmatch.fnmatch(normalized_path, pattern):
                return True

    return False


def extract_resp_files_from_command(command: str) -> Set[str]:
    """
    Extract response file references from a compiler command string.
    
    Response files are referenced with @ syntax: @/path/to/file.resp
    """
    resp_files = set()

    # Pattern for response files: @/path/to/file.resp
    pattern = r'@([^\s]+\.resp)'
    matches = re.findall(pattern, command)

    for match in matches:
        # Clean up the path
        path = match.strip('"\'')
        if path:
            resp_files.add(path)

    return resp_files


def parse_resp_file(resp_file_path: str) -> Set[str]:
    """
    Parse a response file and extract include paths from it.
    """
    include_paths = set()

    try:
        with open(resp_file_path, 'r', encoding='utf-8') as f:
            content = f.read()

        # Extract include paths from the response file content
        paths = extract_include_paths_from_command(content)
        include_paths.update(paths)

    except FileNotFoundError:
        print(f"Warning: Response file {resp_file_path} not found")
    except Exception as e:
        print(f"Warning: Error reading response file {resp_file_path}: {e}")

    return include_paths


def parse_compile_commands(file_path: str) -> Set[str]:
    """
    Parse compile_commands.json and extract all unique include paths.
    """
    all_include_paths = set()
    all_resp_files = set()

    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            compile_commands = json.load(f)

        if not isinstance(compile_commands, list):
            print(f"Warning: Expected array in {file_path}, got {type(compile_commands)}")
            return all_include_paths

        for entry in compile_commands:
            if not isinstance(entry, dict):
                continue

            # Extract from 'command' field
            if 'command' in entry:
                command = entry['command']

                # Extract direct include paths
                paths = extract_include_paths_from_command(command)
                all_include_paths.update(paths)

                # Extract response file references
                resp_files = extract_resp_files_from_command(command)
                all_resp_files.update(resp_files)

            # Extract from 'arguments' field (alternative format)
            elif 'arguments' in entry and isinstance(entry['arguments'], list):
                command = ' '.join(entry['arguments'])

                # Extract direct include paths
                paths = extract_include_paths_from_command(command)
                all_include_paths.update(paths)

                # Extract response file references
                resp_files = extract_resp_files_from_command(command)
                all_resp_files.update(resp_files)

        # Process all found response files
        print(f"Found {len(all_resp_files)} unique response files")
        for resp_file in all_resp_files:
            resp_paths = parse_resp_file(resp_file)
            all_include_paths.update(resp_paths)
            if resp_paths:
                print(f"  Extracted {len(resp_paths)} paths from {resp_file}")

    except FileNotFoundError:
        print(f"Error: File {file_path} not found")
        return set()
    except json.JSONDecodeError as e:
        print(f"Error parsing JSON in {file_path}: {e}")
        return set()
    except Exception as e:
        print(f"Error processing {file_path}: {e}")
        return set()

    return all_include_paths


def normalize_paths(paths: Set[str], base_dir: str) -> List[str]:
    """
    Normalize and sort include paths.
    Convert workspace paths to relative, others to absolute.
    Apply filtering based on ignore patterns and optionally filter non-existent paths.
    """
    normalized = []
    filtered_count = 0
    non_existent_count = 0
    base_path = Path(base_dir).resolve()

    for path in paths:
        # Check if path should be ignored
        if should_ignore_path(path):
            filtered_count += 1
            continue

        try:
            path_obj = Path(path)

            # Convert relative paths to absolute for processing
            if not path_obj.is_absolute():
                path_obj = base_path / path_obj

            # Check if path exists on disk (if filtering is enabled)
            if FILTER_NON_EXISTENT_PATHS and not path_obj.exists():
                non_existent_count += 1
                continue

            # Resolve to canonical path if it exists
            if path_obj.exists():
                resolved_path = path_obj.resolve()
            else:
                resolved_path = path_obj

            # Convert workspace paths to relative paths
            try:
                if resolved_path.is_relative_to(base_path):
                    relative_path = resolved_path.relative_to(base_path)
                    final_path = str(relative_path)
                else:
                    # Keep absolute path for non-workspace paths
                    final_path = str(resolved_path)
            except (ValueError, AttributeError):
                # Fallback for older Python versions or edge cases
                resolved_str = str(resolved_path)
                base_str = str(base_path)
                if resolved_str.startswith(base_str):
                    # Remove base path and leading slash to make relative
                    relative_str = resolved_str[len(base_str):].lstrip('/')
                    if relative_str:  # Don't add empty string
                        final_path = relative_str
                    else:
                        continue  # Skip empty paths
                else:
                    final_path = resolved_str

            # Apply ignore filter to the final normalized path as well
            if not should_ignore_path(final_path):
                normalized.append(final_path)
            else:
                filtered_count += 1

        except Exception:
            # If path processing fails, keep original if not ignored and exists
            path_obj = Path(path)
            if not path_obj.is_absolute():
                path_obj = base_path / path_obj

            if FILTER_NON_EXISTENT_PATHS and not path_obj.exists():
                non_existent_count += 1
                continue

            if not should_ignore_path(path):
                normalized.append(path)
            else:
                filtered_count += 1

    if filtered_count > 0:
        print(f"Filtered out {filtered_count} paths based on ignore patterns")

    if FILTER_NON_EXISTENT_PATHS and non_existent_count > 0:
        print(f"Filtered out {non_existent_count} paths that do not exist on disk")

    # Remove duplicates and sort
    return sorted(set(normalized))


def write_include_paths_log(paths: List[str], output_file: str):
    """
    Write include paths to the output log file.
    """
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            for i, path in enumerate(paths):
                # Add quotes around each path and a comma at the end
                # Remove comma from the last item to make valid JSON
                if i == len(paths) - 1:
                    f.write(f'"{path}"\n')
                else:
                    f.write(f'"{path}",\n')

        print(f"Successfully wrote {len(paths)} include paths to {output_file}")

    except Exception as e:
        print(f"Error writing to {output_file}: {e}")
        sys.exit(1)


def main():
    """
    Main function to extract include paths and write to log file.
    """
    # Configuration
    compile_commands_path = ".vscode/.build/compile_commands.json"
    output_file = ".vscode/.build/compile_commands_include_paths.log"

    # Check if compile_commands.json exists
    if not os.path.exists(compile_commands_path):
        print(f"Error: {compile_commands_path} not found")
        sys.exit(1)

    print(f"Processing: {compile_commands_path}")

    # Extract include paths
    include_paths = parse_compile_commands(compile_commands_path)

    if not include_paths:
        print("No include paths found in compile_commands.json")
        sys.exit(1)

    print(f"Found {len(include_paths)} unique include paths")

    # Normalize paths
    current_dir = os.getcwd()
    normalized_paths = normalize_paths(include_paths, current_dir)

    # Write to output file
    write_include_paths_log(normalized_paths, output_file)

    # Print summary
    print(f"\nSummary:")
    print(f"- Processed: {compile_commands_path}")
    print(f"- Found: {len(include_paths)} unique paths (including response files)")
    print(f"- Normalized: {len(normalized_paths)} paths")
    print(f"- Output: {output_file}")


if __name__ == "__main__":
    main()
